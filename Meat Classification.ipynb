{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9dcd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_encoding = {\n",
    "    'SPOILED': 0,\n",
    "    'HALF': 1,\n",
    "    'FRESH': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33ec2a",
   "metadata": {},
   "source": [
    "# Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(file_path, output_x, output_y):\n",
    "    for file_name in os.listdir(file_path):\n",
    "        class_name = file_name.split('-')[0]\n",
    "        if (class_name == '_classes.csv'): continue\n",
    "        img = cv.imread(file_path + file_name).astype('float32')\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img = cv.resize(img, (128, 128), interpolation = cv.INTER_AREA)\n",
    "        img /= 255\n",
    "        output_x.append(img)\n",
    "        output_y.append(class_label_encoding[class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ac2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "load_images('data/train/', train_x, train_y)\n",
    "load_images('data/valid/', test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7633df5c",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d60903",
   "metadata": {},
   "source": [
    "## Color Histogram\n",
    "Jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins=32):\n",
    "    \"\"\"\n",
    "    Extract color histogram features from an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The input image (should be in RGB format)\n",
    "    - bins: Number of bins for the histogram\n",
    "    \n",
    "    Returns:\n",
    "    - histogram_features: Flattened histogram features\n",
    "    \"\"\"\n",
    "    # Extract histograms for each channel\n",
    "    hist_r = cv.calcHist([image], [0], None, [bins], [0, 1])  # Changed range to [0, 1] since you're normalizing images\n",
    "    hist_g = cv.calcHist([image], [1], None, [bins], [0, 1])\n",
    "    hist_b = cv.calcHist([image], [2], None, [bins], [0, 1])\n",
    "    \n",
    "    # Normalize the histograms\n",
    "    cv.normalize(hist_r, hist_r, 0, 1, cv.NORM_MINMAX)\n",
    "    cv.normalize(hist_g, hist_g, 0, 1, cv.NORM_MINMAX)\n",
    "    cv.normalize(hist_b, hist_b, 0, 1, cv.NORM_MINMAX)\n",
    "    \n",
    "    # Flatten and concatenate the histograms\n",
    "    histogram_features = np.concatenate([\n",
    "        hist_r.flatten(), \n",
    "        hist_g.flatten(), \n",
    "        hist_b.flatten()\n",
    "    ])\n",
    "    \n",
    "    return histogram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69713c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_histogram(image, bins=32, title=\"Color Histogram\"):\n",
    "    \"\"\"\n",
    "    Plot the color histogram of an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The input image (should be in RGB format)\n",
    "    - bins: Number of bins for the histogram\n",
    "    - title: Title for the plot\n",
    "    \n",
    "    Returns:\n",
    "    - None (displays the plot)\n",
    "    \"\"\"\n",
    "    # Create a figure with subplots\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    # Display the original image\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    # Get histogram features using your existing function\n",
    "    features = extract_color_histogram(image, bins)\n",
    "    \n",
    "    # Split the features back into channels\n",
    "    channel_length = len(features) // 3\n",
    "    hist_r = features[:channel_length].reshape(bins, 1)\n",
    "    hist_g = features[channel_length:2*channel_length].reshape(bins, 1)\n",
    "    hist_b = features[2*channel_length:].reshape(bins, 1)\n",
    "    \n",
    "    # Define colors and channels\n",
    "    colors = ['r', 'g', 'b']\n",
    "    channels = ['Red', 'Green', 'Blue']\n",
    "    hists = [hist_r, hist_g, hist_b]\n",
    "    \n",
    "    # Plot histograms for each channel\n",
    "    for i, (hist, col, chan) in enumerate(zip(hists, colors, channels)):\n",
    "        ax[i+1].plot(hist, color=col)\n",
    "        ax[i+1].set_xlim([0, bins])\n",
    "        ax[i+1].set_title(f'{chan} Histogram')\n",
    "        ax[i+1].set_xlabel('Bins')\n",
    "        ax[i+1].set_ylabel('# of Pixels')\n",
    "        ax[i+1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_x[0]  # Get the first image\n",
    "plot_color_histogram(image, bins=32, title=\"Meat Sample Color Histogram\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16684164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from training and testing sets\n",
    "train_features = []\n",
    "for img in train_x:\n",
    "    hist_features = extract_color_histogram(img)\n",
    "    train_features.append(hist_features)\n",
    "train_features = np.array(train_features)\n",
    "\n",
    "\n",
    "test_features = []\n",
    "for img in test_x:\n",
    "    hist_features = extract_color_histogram(img)\n",
    "    test_features.append(hist_features)\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c288bd",
   "metadata": {},
   "source": [
    "## Local Binary Pattern\n",
    "Aiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0966dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel(img, center, x, y):\n",
    "    \"\"\"\n",
    "    Gets Local Binary Patterns values for pixel adjacent to the selected one.\n",
    "    \n",
    "    Parameters:\n",
    "    - img: The image containing the pixels\n",
    "    - center: The pixel Local Binary Patterns is being applied to\n",
    "    - x: The x coordinate of the adjacent pixel\n",
    "    - y: The y coordinate of the adjacent pixel\n",
    "    \n",
    "    Returns:\n",
    "    - new_val: The output value for the comparison between the center pixel and the adjacent pixel\n",
    "    \"\"\"\n",
    "    new_value = 0\n",
    "      \n",
    "    try: \n",
    "        # if local neighbourhood pixel value is greater than or equal to center pixel values then set it to 1 \n",
    "        if img[x][y] >= center: \n",
    "            new_value = 1\n",
    "              \n",
    "    except: \n",
    "        # exception required when neighbourhood value of center pixel value is null\n",
    "        pass\n",
    "      \n",
    "    return new_value \n",
    "   \n",
    "# Function for calculating LBP \n",
    "def lbp_calculated_pixel(img, x, y):\n",
    "    \"\"\"\n",
    "    Apply the Local Binary Patterns to a single pixel.\n",
    "    \n",
    "    Parameters:\n",
    "    - img: The image containing the pixel\n",
    "    - x: The x coordinate of the selected pixel\n",
    "    - y: The y coordinate of the selected pixel\n",
    "    \n",
    "    Returns:\n",
    "    - val: The output value for the selected pixel after applying Local Binary Patterns\n",
    "    \"\"\"\n",
    "    center = img[x][y] \n",
    "   \n",
    "    val_ar = [] \n",
    "      \n",
    "    # top_left \n",
    "    val_ar.append(get_pixel(img, center, x-1, y-1)) \n",
    "      \n",
    "    # top \n",
    "    val_ar.append(get_pixel(img, center, x-1, y)) \n",
    "      \n",
    "    # top_right \n",
    "    val_ar.append(get_pixel(img, center, x-1, y + 1)) \n",
    "      \n",
    "    # right \n",
    "    val_ar.append(get_pixel(img, center, x, y + 1)) \n",
    "      \n",
    "    # bottom_right \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y + 1)) \n",
    "      \n",
    "    # bottom \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y)) \n",
    "      \n",
    "    # bottom_left \n",
    "    val_ar.append(get_pixel(img, center, x + 1, y-1)) \n",
    "      \n",
    "    # left \n",
    "    val_ar.append(get_pixel(img, center, x, y-1)) \n",
    "       \n",
    "    # convert binary values to decimal \n",
    "    power_val = [1, 2, 4, 8, 16, 32, 64, 128] \n",
    "   \n",
    "    val = 0\n",
    "      \n",
    "    for i in range(len(val_ar)): \n",
    "        val += val_ar[i] * power_val[i] \n",
    "          \n",
    "    return val\n",
    "\n",
    "\n",
    "def lbp_output(img_bgr):\n",
    "    \"\"\"\n",
    "    Apply the Local Binary Patterns filter to an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - img_bgr: The image to be transformed\n",
    "    \n",
    "    Returns:\n",
    "    - image_lbp: The output image with the Local Binary Patterns filter applied\n",
    "    \"\"\"\n",
    "    height, width, _ = img_bgr.shape \n",
    "   \n",
    "    # convert RGB to gray \n",
    "    img_gray = cv.cvtColor(img_bgr, \n",
    "                            cv.COLOR_BGR2GRAY) \n",
    "       \n",
    "    # create numpy array as same height and width of RGB image \n",
    "    img_lbp = np.zeros((height, width), \n",
    "                       np.float32) \n",
    "       \n",
    "    for i in range(0, height): \n",
    "        for j in range(0, width): \n",
    "            img_lbp[i, j] = lbp_calculated_pixel(img_gray, i, j)\n",
    "\n",
    "    return img_lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9387764",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = train_x[0]\n",
    "img_lbp = lbp_output(img_bgr)\n",
    "  \n",
    "plt.imshow(img_bgr) \n",
    "plt.show()\n",
    "   \n",
    "plt.imshow(img_lbp, cmap =\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab348b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_lbp(imgs, labels, train_test='train'):\n",
    "    \"\"\"\n",
    "    Save images with the Local Binary Patterns filter applied and unique file names based on label.\n",
    "    \n",
    "    Parameters:\n",
    "    - imgs: List of images to be transformed\n",
    "    - labels: List of labels for each image\n",
    "    - train_test: The string value either 'train' or 'test' which determines the output directory\n",
    "    \"\"\"\n",
    "    label_text = ['SPOILED', 'HALF', 'FRESH']\n",
    "    for image in range(len(imgs)):\n",
    "        lbp_image = lbp_output(imgs[image])\n",
    "        filename = f'data/lbp/{train_test}/{label_text[labels[image]]}-{image}-lbp.jpg'\n",
    "        cv.imwrite(filename, lbp_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_images_lbp(train_x, train_y, train_test='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff94ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_images_lbp(test_x, test_y, train_test='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f715356b",
   "metadata": {},
   "source": [
    "## Histograms of Oriented Gradients\n",
    "Fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5931aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from here: https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_hog.html\n",
    "def make_hog(image, visualize=False):\n",
    "    features, hog_image = hog(\n",
    "            image,\n",
    "            orientations=8,\n",
    "            pixels_per_cell=(16, 16),\n",
    "            cells_per_block=(1, 1),\n",
    "            visualize=True,\n",
    "            channel_axis=-1\n",
    "        )\n",
    "\n",
    "    if visualize:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "        ax1.axis('off')\n",
    "        ax1.imshow(image, cmap=plt.cm.gray)\n",
    "        ax1.set_title('Input image')\n",
    "\n",
    "        hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "        ax2.axis('off')\n",
    "        ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "        ax2.set_title('Histogram of Oriented Gradients')\n",
    "        plt.show()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19806fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_hog(train_x[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_hog = []\n",
    "test_features_hog = []\n",
    "\n",
    "for image in train_x:\n",
    "    train_features_hog.append(make_hog(image))\n",
    "\n",
    "for image in test_x:\n",
    "    test_features_hog.append(make_hog(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12472a7b",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3fac7a",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4491c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(x_train_tree, y_train_tree, x_test_tree, y_test_tree, max_depth=5, show_tree=True, feature_names=None):\n",
    "    \"\"\"\n",
    "    Train a decision tree classifier on any type of features, with optional histogram visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_train_tree: Training features\n",
    "    - y_train_tree: Training labels\n",
    "    - x_test_tree: Test features\n",
    "    - y_test_tree: Test labels\n",
    "    - max_depth: Maximum depth of the decision tree\n",
    "    - show_tree: Whether to visualize the decision tree\n",
    "    - feature_names: Names of features (will be auto-generated if None)\n",
    "    \n",
    "    Returns:\n",
    "    - dt_classifier: Trained decision tree classifier\n",
    "    - accuracy: Classification accuracy on test set\n",
    "    - report: Classification report\n",
    "    - conf_matrix: Confusion matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list of class names\n",
    "    class_names=['SPOILED', 'HALF', 'FRESH']\n",
    "    \n",
    "    # Create and train a Decision Tree classifier\n",
    "    dt_classifier = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    dt_classifier.fit(x_train_tree, y_train_tree)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = dt_classifier.predict(x_test_tree)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test_tree, predictions)\n",
    "    report = classification_report(y_test_tree, predictions, target_names=class_names)\n",
    "    conf_matrix = confusion_matrix(y_test_tree, predictions)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Decision Tree Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Add text annotations in the confusion matrix\n",
    "    thresh = conf_matrix.max() / 2\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Show decision tree if requested\n",
    "    if show_tree:\n",
    "        # Create feature names if not provided\n",
    "        if feature_names is None:\n",
    "            feature_names = [f\"Feature_{i}\" for i in range(x_train_tree.shape[1])]\n",
    "            \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plot_tree(dt_classifier, \n",
    "                  feature_names=feature_names,\n",
    "                  class_names=class_names,\n",
    "                  filled=True, \n",
    "                  rounded=True, \n",
    "                  fontsize=8)\n",
    "        plt.title(\"Decision Tree for Classification\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return dt_classifier, accuracy, report, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e749fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create feature names for the histogram features\n",
    "# bins_per_channel = train_features.shape[1] // 3\n",
    "# channels = ['Red', 'Green', 'Blue']\n",
    "# feature_names = []\n",
    "# for channel in channels:\n",
    "#     for index in range(bins_per_channel):\n",
    "#         feature_names.append(f\"{channel} Bin {index}\")\n",
    "\n",
    "# #x_train_tree, y_train_tree, x_test_tree, y_test_tree, max_depth=5, show_tree=True, feature_names=None\n",
    "\n",
    "# # Train the decision tree with histogram visualization\n",
    "# model, acc, report = train_decision_tree(x_train_tree=train_features, y_train_tree=train_y, x_test_tree=test_features,\n",
    "#                                          y_test_tree=test_y, max_depth=3, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c27a7c6",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Aiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9584d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(x_train_forest, y_train_forest, x_test_forest, y_test_forest, n_estimators=100, criterion='gini', max_depth=None,\n",
    "                        min_samples_split=2, min_samples_leaf=1, max_features='sqrt'):\n",
    "    \"\"\"\n",
    "    Train and generate evaluation metrics for a Random Forest classifier given training and testing data.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_train_forest: Training data\n",
    "    - y_train_forest: Training labels\n",
    "    - x_test_forest: Test data\n",
    "    - y_test_forest: Test labels\n",
    "    - n_estimators: The number of trees in the forest\n",
    "    - criterion: The function to measure the quality of a split\n",
    "    - max_depth: Maximum depth of the tree\n",
    "    - min_samples_split: The minimum number of samples required to split an internal node\n",
    "    - min_samples_leaf: The minimum number of samples required to be at a leaf node\n",
    "    - max_features: The number of features to consider when looking for the best split\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy: The accuracy score for the model's predictions\n",
    "    - precision: The precision score for the model's predictions\n",
    "    - recall: The recall score for the model's predictions\n",
    "    - f1: The f1 score for the model's predictions\n",
    "    - confusion: The confusion matrix fro the model's predictions\n",
    "    \"\"\"\n",
    "    # Create Random Forest classifer object\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                min_samples_leaf=min_samples_leaf, max_features=max_features, random_state=42)\n",
    "    \n",
    "    # Train Random Forest Classifer\n",
    "    clf.fit(x_train_forest,y_train_forest)\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(x_test_forest)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_forest, y_pred)\n",
    "    precision = precision_score(y_test_forest, y_pred)\n",
    "    recall = recall_score(y_test_forest, y_pred)\n",
    "    f1 = f1_score(y_test_forest, y_pred)\n",
    "    confusion = confusion_matrix(y_test_forest, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1, confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcd224-533a-483f-a11a-a3eec1bde255",
   "metadata": {},
   "source": [
    "## Random Forest Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1683976b-1114-4bc0-9fc4-533f4c3adbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rf(rf_train_x, rf_train_y, rf_test_x, rf_test_y):\n",
    "    \"\"\"\n",
    "    Run a series of tests with different combinations of hyperparameters for the Random Forest classifier.\n",
    "    \n",
    "    Parameters:\n",
    "    - rf_train_x: Training data\n",
    "    - rf_train_y: Training lables\n",
    "    - rf_test_x: Test data\n",
    "    - rf_test_y: Test labels\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame(all_tests): The dataframe containing all hyperparameter values and results for each test\n",
    "    - confusion: List of confusion matrices for each test\n",
    "    \"\"\"\n",
    "    # Hyperparameter tuning values\n",
    "    all_n_estimators = [10,50,100,500,1000]\n",
    "    all_criterion = ['gini', 'entropy', 'log_loss']\n",
    "    all_max_depth = [None]\n",
    "    all_min_samples_split = [2]\n",
    "    all_min_samples_leaf = [1]\n",
    "    all_max_features = ['sqrt', 'log2', None]\n",
    "\n",
    "    # Run tests with all combinations and output results\n",
    "    all_tests = {'n_estimators': [], 'criterion': [], 'max_depth': [], 'min_samples_split': [], 'min_samples_leaf': [], 'max_features': [],\n",
    "                'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    confusion_matrices = []\n",
    "    for n_estimators in all_n_estimators:\n",
    "        for criterion in all_criterion:\n",
    "            for max_depth in all_max_depth:\n",
    "                for min_samples_split in all_min_samples_split:\n",
    "                    for min_samples_leaf in all_min_samples_leaf:\n",
    "                        for max_features in all_max_features:\n",
    "                            all_tests['n_estimators'].append(n_estimators)\n",
    "                            all_tests['criterion'].append(criterion)\n",
    "                            all_tests['max_depth'].append(max_depth)\n",
    "                            all_tests['min_samples_split'].append(min_samples_split)\n",
    "                            all_tests['min_samples_leaf'].append(min_samples_leaf)\n",
    "                            all_tests['max_features'].append(max_features)\n",
    "                            accuracy, precision, recall, f1, confusion = train_random_forest(rf_train_x, rf_train_y, rf_test_x, rf_test_y, n_estimators,\n",
    "                                                                                            criterion, max_depth, min_samples_split, min_samples_leaf,\n",
    "                                                                                            max_features)\n",
    "                            for i, feature in enumerate(all_tests):\n",
    "                                feature_vals = [n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, max_features,\n",
    "                                               accuracy, precision, recall, f1]\n",
    "                                all_tests[feature].append(feature_vals[i])\n",
    "                            confusion_matrices.append(confusion)\n",
    "\n",
    "    return pd.DataFrame(all_tests), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb8056",
   "metadata": {},
   "source": [
    "## Knn\n",
    "Fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f7cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(x_train, y_train, n_neighbors=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc64b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_report(knn, x_test, y_test):\n",
    "    predictions = knn.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    report = classification_report(y_test, predictions, target_names=['SPOILED', 'HALF', 'FRESH'])\n",
    "    print(f\"Knn Accuracy: {accuracy:.4f}\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab70cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from here: https://medium.com/@agrawalsam1997/hyperparameter-tuning-of-knn-classifier-a32f31af25c7\n",
    "def tune_knn(x_train, y_train, x_test, y_test, title,\n",
    "             n_start=1, n_stop=10, n_step=1):\n",
    "    train_scores = {}\n",
    "    test_scores = {}\n",
    "    f1_scores = {}\n",
    "    models = {}\n",
    "\n",
    "    n_neighbors = np.arange(n_start, n_stop, n_step)\n",
    "    for n in n_neighbors:\n",
    "        knn = train_knn(x_train, y_train, n_neighbors=n)\n",
    "        train_scores[n] = knn.score(x_train, y_train)\n",
    "        test_scores[n] = knn.score(x_test, y_test)\n",
    "        f1_scores[n] = f1_score(y_test, knn.predict(x_test), average='macro')\n",
    "        models[n] = knn\n",
    "\n",
    "    plt.plot(n_neighbors, train_scores.values(), label=\"Train Accuracy\")\n",
    "    plt.plot(n_neighbors, test_scores.values(), label=\"Test Accuracy\")\n",
    "    plt.plot(n_neighbors, f1_scores.values(), label=\"F1 Score\", linestyle='--')\n",
    "    plt.xlabel(\"Number of Neighbors\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"KNN ({title}): Varying Number of Neighbors\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767818b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HOG\")\n",
    "knn = train_knn(train_features_hog, train_y)\n",
    "knn_report(knn, test_features_hog, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune_knn(train_features, train_y, test_features, test_y, \"Color Histograms\", n_stop=50)\n",
    "#tune_knn(train_features_hog, train_y, test_features_hog, test_y, \"HOG\", n_stop=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9b1c5-0b4a-4a21-91f6-63793b96d9a2",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "Aiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacbac2-f233-449f-8c57-eba8173239ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x_train_mlp, y_train_mlp, x_test_mlp, y_test_mlp, hidden_layer_sizes, max_iter=100, activation='relu'):\n",
    "    \"\"\"\n",
    "    Train and generate evaluation metrics for an MLP classifier given training and testing data.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_train_mlp: Training data\n",
    "    - y_train_mlp: Training labels\n",
    "    - x_test_mlp: Test data\n",
    "    - y_test_mlp: Test labels\n",
    "    - hidden_layer_sizes: The size of each hidden layer in tuple form (each entry is a hidden layer)\n",
    "    - max_iter: The number of iterations for tuning weights and biases\n",
    "    - activation: The activation function of the perceptrons\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy: The accuracy score for the model's predictions\n",
    "    - precision: The precision score for the model's predictions\n",
    "    - recall: The recall score for the model's predictions\n",
    "    - f1: The f1 score for the model's predictions\n",
    "    - confusion: The confusion matrix fro the model's predictions\n",
    "    \"\"\"\n",
    "    # Create MLP classifer object\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, activation=activation)\n",
    "    \n",
    "    # Train MLP Classifer\n",
    "    mlp.fit(x_train_mlp,y_train_mlp)\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = mlp.predict(x_test_mlp)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_mlp, y_pred)\n",
    "    precision = precision_score(y_test_mlp, y_pred)\n",
    "    recall = recall_score(y_test_mlp, y_pred)\n",
    "    f1 = f1_score(y_test_mlp, y_pred)\n",
    "    confusion = confusion_matrix(y_test_mlp, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1, confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f089fc7-97df-4497-987d-9346cad55735",
   "metadata": {},
   "source": [
    "## Neural Network Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ea140-d70f-410d-9964-0632926fb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(nn_train_x, nn_train_y, nn_test_x, nn_test_y):\n",
    "    \"\"\"\n",
    "    Run a series of tests with different combinations of hyperparameters for the MLP classifier.\n",
    "    \n",
    "    Parameters:\n",
    "    - nn_train_x: Training data\n",
    "    - nn_train_y: Training lables\n",
    "    - nn_test_x: Test data\n",
    "    - nn_test_y: Test labels\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame(all_tests): The dataframe containing all hyperparameter values and results for each test\n",
    "    - confusion: List of confusion matrices for each test\n",
    "    \"\"\"\n",
    "    # Hyperparameter tuning values\n",
    "    all_hidden_layer_sizes = [(128,64,32,16,8,4), (64,32,16,8,4), (32,16,8,4), (16,8,4), (8,4), (4)]\n",
    "    all_max_iter = [1000, 100, 10]\n",
    "    all_activation = ['relu', 'logistic']\n",
    "\n",
    "    # Run tests with all combinations and output results\n",
    "    all_tests = {'hidden_layer_sizes': [], 'max_iter': [], 'activation': [],\n",
    "                'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    confusion_matrices = []\n",
    "    for hidden_layer_sizes in all_hidden_layer_sizes:\n",
    "        for max_iter in all_max_iter:\n",
    "            for activation in all_activation:\n",
    "                all_tests['hidden_layer_sizes'].append(hidden_layer_sizes)\n",
    "                all_tests['max_iter'].append(max_iter)\n",
    "                all_tests['activation'].append(activation)\n",
    "                accuracy, precision, recall, f1, confusion = train_neural_network(nn_train_x, nn_train_y, nn_test_x, nn_test_y, hidden_layer_sizes,\n",
    "                                                                                max_iter, activation)\n",
    "                for i, feature in enumerate(all_tests):\n",
    "                    feature_vals = [hidden_layer_sizes, max_iter, activation, accuracy, precision, recall, f1]\n",
    "                    all_tests[feature].append(feature_vals[i])\n",
    "                confusion_matrices.append(confusion)\n",
    "\n",
    "    return pd.DataFrame(all_tests), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e84e7e-7fab-44d5-9898-57e6257dd6ef",
   "metadata": {},
   "source": [
    "# PCA Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5fa06-9336-482b-b40c-d4a066911529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pca(xColumns, components=2):\n",
    "    pca = PCA(n_components = components)\n",
    "    data_pca = pca.fit_transform(xColumns)\n",
    "    return data_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a967b821-b396-4688-97fc-f8d755597d32",
   "metadata": {},
   "source": [
    "# Create Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356c2d2-b549-4210-96a6-e95ca1487a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images_to_dataframe(images, filter_type, pca_components=2, labels=None):\n",
    "    \"\"\"\n",
    "    Transform a set of images into a pandas DataFrame with PCA of extracted features.\n",
    "    \n",
    "    Parameters:\n",
    "    - images: List of images (numpy arrays)\n",
    "    - filter_type: Type of feature extraction ('HIS', 'LBP', or 'HOG')\n",
    "    - pca_components: Number of PCA components to keep (default=2)\n",
    "    - labels: Optional list of labels for the images\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with PCA components and labels (if provided)\n",
    "    \"\"\"\n",
    "    # Extract features from all images\n",
    "    all_features = []\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        if filter_type.upper() == \"HIS\":\n",
    "            # Extract color histogram features\n",
    "            features = extract_color_histogram(img)\n",
    "        \n",
    "        elif filter_type.upper() == \"LBP\":\n",
    "            # Extract LBP features\n",
    "            lbp_img = lbp_output(img)\n",
    "            features = lbp_img.flatten()\n",
    "        \n",
    "        elif filter_type.upper() == \"HOG\":\n",
    "            # Extract HOG features\n",
    "            features = make_hog(img)\n",
    "        \n",
    "        all_features.append(features)\n",
    "    \n",
    "    # Convert to numpy array for PCA\n",
    "    feature_array = np.array(all_features)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca_result = do_pca(feature_array, components=pca_components)\n",
    "    \n",
    "    # Create DataFrame with PCA results\n",
    "    columns = [f'pca_{i+1}' for i in range(pca_components)]\n",
    "    df = pd.DataFrame(pca_result, columns=columns)\n",
    "    \n",
    "    # Add label if provided\n",
    "    if labels is not None:\n",
    "        df['label'] = labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c664f2-fe2e-4282-b91d-261b14913ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data into a DataFrame\n",
    "train_df_hist = transform_images_to_dataframe(train_x, \"HIS\", pca_components=16)\n",
    "\n",
    "# Transform testing data into a DataFrame\n",
    "test_df_hist = transform_images_to_dataframe(test_x, \"HIS\", pca_components=16)\n",
    "\n",
    "# Transform training data into a DataFrame\n",
    "train_df_lbp = transform_images_to_dataframe(train_x, \"lbp\")\n",
    "\n",
    "# Transform testing data into a DataFrame\n",
    "test_df_lbp = transform_images_to_dataframe(test_x, \"lbp\")\n",
    "\n",
    "# Transform training data into a DataFrame\n",
    "train_df_hog = transform_images_to_dataframe(train_x, \"hog\")\n",
    "\n",
    "# Transform testing data into a DataFrame\n",
    "test_df_hog = transform_images_to_dataframe(test_x, \"hog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac4c40-d709-46dc-ba5e-56a750e3b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_hist.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3c9ec-af1c-497a-88ef-e04c0fe56167",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lbp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969da71-8a7b-4bb8-9c67-af0239eb7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_hog.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8ed2f4-a266-447b-84fa-49456c1c956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree_on_pca_dataframes(train_dfs, test_dfs, train_labels, test_labels, feature_names=None, max_depth=3):\n",
    "    \"\"\"\n",
    "    Run decision tree classification on multiple PCA-transformed dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_dfs: Dictionary of training dataframes {'name': dataframe}\n",
    "    - test_dfs: Dictionary of testing dataframes {'name': dataframe}\n",
    "    - train_labels: Training labels\n",
    "    - test_labels: Testing labels\n",
    "    - feature_names: Optional dictionary of feature names for each dataframe\n",
    "    - max_depth: Maximum depth for decision tree\n",
    "    \n",
    "    Returns:\n",
    "    - results: Dictionary containing trained models and their performance metrics\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for name in train_dfs.keys():\n",
    "        print(f\"\\n--- Decision Tree Classification for {name} features ---\")\n",
    "        \n",
    "        # Get the dataframes\n",
    "        train_df = train_dfs[name]\n",
    "        test_df = test_dfs[name]\n",
    "        \n",
    "        # Determine feature names if not provided\n",
    "        names = None\n",
    "        if feature_names and name in feature_names:\n",
    "            names = feature_names[name]\n",
    "        else:\n",
    "            names = train_df.columns.tolist()\n",
    "        \n",
    "        # Train decision tree\n",
    "        model, accuracy, report, conf_matrix = train_decision_tree(\n",
    "            x_train_tree=train_df.values,\n",
    "            y_train_tree=train_labels,\n",
    "            x_test_tree=test_df.values,\n",
    "            y_test_tree=test_labels,\n",
    "            max_depth=max_depth,\n",
    "            show_tree=True,\n",
    "            feature_names=names\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'report': report,\n",
    "            'confusion_matrix': conf_matrix\n",
    "        }\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\n--- Comparison of Decision Tree Results ---\")\n",
    "    for name, result in results.items():\n",
    "        print(f\"{name}: Accuracy = {result['accuracy']:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac421d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = {\n",
    "    'Histogram': train_df_hist,\n",
    "    'LBP': train_df_lbp,\n",
    "    'HOG': train_df_hog\n",
    "}\n",
    "\n",
    "test_dfs = {\n",
    "    'Histogram': test_df_hist,\n",
    "    'LBP': test_df_lbp,\n",
    "    'HOG': test_df_hog\n",
    "}\n",
    "\n",
    "# Define feature names for better visualization\n",
    "pca_components = 16\n",
    "feature_names = {\n",
    "    'Histogram': [f'Histogram PCA {i+1}' for i in range(pca_components)],\n",
    "    'LBP': [f'LBP PCA {i+1}' for i in range(pca_components)],\n",
    "    'HOG': [f'HOG PCA {i+1}' for i in range(pca_components)]\n",
    "}\n",
    "\n",
    "# Run the analysis\n",
    "results = run_decision_tree_on_pca_dataframes(\n",
    "    train_dfs=train_dfs,\n",
    "    test_dfs=test_dfs,\n",
    "    train_labels=train_y,\n",
    "    test_labels=test_y,\n",
    "    feature_names=feature_names,\n",
    "    max_depth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371da765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
